{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Lab 4 - Using Python to Design Classification Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the final lab of the Machine Learning course at CoderSchool! Your final project is to build a *Spotify Music Recommendation System*. \n",
    "\n",
    "In order to do this, you will have to focus on having a good **DESIGN** for your system.\n",
    "\n",
    "A good design means knowing a few things:\n",
    "* Which Classifiers to use\n",
    "* How to Connect them together\n",
    "* How to produce a final \"Score\"\n",
    "\n",
    "You spent the first half of today's lab trying to draw out a design and think of ways to produce your score from your classifiers.\n",
    "\n",
    "Now, we will look at a few Python functions that can help you achieve your design. You don't *have* to use any of these objects; the final project can be completed without using these concepts. But knowing that they exist gives you some more options and you could find them helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "\n",
    "We'll use a consolidated dataset of `Dance`, `Jazz`, `Rock`, and `Rap` from Assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_dataset = pd.read_csv('Consolidated_DF_6000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.618964</td>\n",
       "      <td>0.375099</td>\n",
       "      <td>114.907</td>\n",
       "      <td>0.034430</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>302.37333</td>\n",
       "      <td>-9.496</td>\n",
       "      <td>0.947362</td>\n",
       "      <td>0.905836</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.87</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.844817</td>\n",
       "      <td>0.067792</td>\n",
       "      <td>109.935</td>\n",
       "      <td>0.048568</td>\n",
       "      <td>0.127837</td>\n",
       "      <td>0.910389</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>435.80000</td>\n",
       "      <td>-8.461</td>\n",
       "      <td>0.449367</td>\n",
       "      <td>0.687389</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1.00</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.940507</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>128.046</td>\n",
       "      <td>0.029577</td>\n",
       "      <td>0.034144</td>\n",
       "      <td>0.881883</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>235.62667</td>\n",
       "      <td>-7.588</td>\n",
       "      <td>0.932188</td>\n",
       "      <td>0.728027</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.557</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.965342</td>\n",
       "      <td>0.350438</td>\n",
       "      <td>124.939</td>\n",
       "      <td>0.047233</td>\n",
       "      <td>0.082816</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>198.65333</td>\n",
       "      <td>-6.038</td>\n",
       "      <td>0.778784</td>\n",
       "      <td>0.638805</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.00</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.639406</td>\n",
       "      <td>0.064024</td>\n",
       "      <td>88.306</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.100388</td>\n",
       "      <td>0.941271</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.13333</td>\n",
       "      <td>-6.737</td>\n",
       "      <td>0.719930</td>\n",
       "      <td>0.866491</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1.00</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key    energy  liveliness    tempo  speechiness  acousticness  \\\n",
       "0    6  0.618964    0.375099  114.907     0.034430      0.129149   \n",
       "1    7  0.844817    0.067792  109.935     0.048568      0.127837   \n",
       "2    0  0.940507    0.050800  128.046     0.029577      0.034144   \n",
       "3    0  0.965342    0.350438  124.939     0.047233      0.082816   \n",
       "4    1  0.639406    0.064024   88.306     0.116464      0.100388   \n",
       "\n",
       "   instrumentalness  time_signature  duration   loudness  valence  \\\n",
       "0          0.000397               0         4  302.37333   -9.496   \n",
       "1          0.910389               1         4  435.80000   -8.461   \n",
       "2          0.881883               0         4  235.62667   -7.588   \n",
       "3          0.000383               1         4  198.65333   -6.038   \n",
       "4          0.941271               1         4   65.13333   -6.737   \n",
       "\n",
       "   danceability      mode  time_signature_confidence  tempo_confidence  \\\n",
       "0      0.947362  0.905836                      0.712             0.620   \n",
       "1      0.449367  0.687389                      0.359             0.498   \n",
       "2      0.932188  0.728027                      0.541             0.557   \n",
       "3      0.778784  0.638805                      0.000             0.045   \n",
       "4      0.719930  0.866491                      0.051             0.436   \n",
       "\n",
       "   key_confidence  mode_confidence genres  \n",
       "0           0.828             0.87  dance  \n",
       "1           0.760             1.00  dance  \n",
       "2           1.000             1.00  dance  \n",
       "3           0.687             1.00  dance  \n",
       "4           0.312             1.00  dance  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a 10% split to use for our training and testing. We'll work with `genres` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = songs_dataset.drop('genres', axis=1)\n",
    "y = songs_dataset['genres']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Pipeline` object in Python is a way to simply connect many different processes or steps together. Let's combine the `SelectKBest` step with a `RandomForestClassifier` step to see how we can use a `Pipeline`.\n",
    "\n",
    "First, from `sklearn.pipeline` import `Pipeline`. Then from `sklearn.feature_selection` import `SelectKBest`, and import `RandomForestClassifier` from `sklearn.ensemble`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `RandomForestClassifier` called `rfc`, and a `SelectKBest` object called `selector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "selector = SelectKBest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is tell the `Pipeline` all the different steps that will be involved.\n",
    "\n",
    "We can arrange steps in a list in the follinwg way:\n",
    "`steps = [(<name of step 1>, object 1), (<name of step 2>, object 2), etc.]`\n",
    "\n",
    "So for our example, we can use something like\n",
    "`steps = [('feature_selection', selector), ('random_forest', rfc)]`\n",
    "\n",
    "Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('feature_selection', selector), ('random_forest', rfc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to make a `Pipeline`, simply pass the `steps` to our `Pipeline` object in the following way:<br>\n",
    "`pipeline = Pipeline(steps)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call `.fit`, and `.predict` on our `pipeline` object just like any other model!\n",
    "\n",
    "Call `.fit`, `.predict`, and then print the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      dance       0.72      0.73      0.72       148\n",
      "       jazz       0.76      0.86      0.81       154\n",
      "        rap       0.82      0.79      0.80       151\n",
      "       rock       0.74      0.65      0.69       147\n",
      "\n",
      "avg / total       0.76      0.76      0.76       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining GridSearchCV and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool thing about a `Pipeline` is that you can use a single `GridSearchCV` object to try different combinations for different values! \n",
    "\n",
    "from `sklearn.grid_search` import `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try 2 values of `k` for `SelectKBest`, 2 values for `n_estimators` and 2 values for the `min_samples_split` for our `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use the following syntax for defining the parameters:\n",
    "* `<name of step in pipeline> + '__' + <name of parameter>`.\n",
    "\n",
    "For example:\n",
    "* the name of our `SelectKBest` step in our pipeline is `feature_selection`\n",
    "* we want to change the `k` value\n",
    "* so the syntax is: `feature_selection__k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(feature_selection__k=[5,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify `parameters` above to add the following values for the `RandomForestClassifier` step as well:<br>\n",
    " `n_estimators: [50, 100]\n",
    " min_samples_split: [2,10]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(feature_selection__k=[5, 10], \n",
    "              random_forest__n_estimators=[50, 100],\n",
    "              random_forest__min_samples_split=[2, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you know how to use `GridSearchCV` -- call it on your `pipeline` object, passing in your new `parameters`. Set `verbose=3` so you can see it in action! Call `.fit` and `.predict` on your `GridSearchCV` object and print the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=50, score=0.739034 -   0.5s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=50, score=0.710161 -   0.5s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=50, score=0.740267 -   0.5s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=100, score=0.735702 -   0.9s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=100, score=0.706274 -   0.9s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=2, random_forest__n_estimators=100, score=0.746385 -   0.9s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=50, score=0.729039 -   0.4s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=50, score=0.712937 -   0.5s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=50, score=0.748053 -   0.4s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=100, score=0.744031 -   0.9s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=100, score=0.715713 -   0.9s\n",
      "[CV] feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=5, random_forest__min_samples_split=10, random_forest__n_estimators=100, score=0.749722 -   0.9s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=50, score=0.776791 -   0.6s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=50, score=0.772904 -   0.6s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=50, score=0.790879 -   0.6s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=100, score=0.782343 -   1.2s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=100, score=0.775125 -   1.2s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=2, random_forest__n_estimators=100, score=0.795328 -   1.2s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=50, score=0.774570 -   0.5s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=50, score=0.776235 -   0.6s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=50 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=50, score=0.791435 -   0.6s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=100, score=0.776235 -   1.1s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=100, score=0.773459 -   1.1s\n",
      "[CV] feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=100 \n",
      "[CV]  feature_selection__k=10, random_forest__min_samples_split=10, random_forest__n_estimators=100, score=0.788654 -   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      dance       0.79      0.69      0.74       148\n",
      "       jazz       0.77      0.87      0.82       154\n",
      "        rap       0.81      0.82      0.82       151\n",
      "       rock       0.74      0.73      0.74       147\n",
      "\n",
      "avg / total       0.78      0.78      0.78       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=parameters, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling\n",
    "\n",
    "'Pickling' is a way to save your python objects to disk. You can simply save ANY python variable to your computer as a `.pickle` file and later read it. It saves time and will help you when testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "some_model = [1, 2, 3, 4, 5, 6]\n",
    "print(some_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to save your object is to call `pickle.dump`. You pass in a filename with a `.pickle` extension (in this case, `my_model.pickle`). `wb` means we are in write mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(some_model, open('my_model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to load your object is to call `pickle.load`. You pass in the filename that you want to load. `rb` means we are in read mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "some_model_2 = pickle.load(open('my_model.pickle', 'rb'))\n",
    "print(some_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, we used a list, but you can use almost any object -- a pandas DataFrame, a RandomForestClassifier model, a Doc2Vec model, a Bag Of Words matrix - almost **ANYTHING** !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A song can be *both* `happy` and `celebratory`. For this reason, `moods` is an example of a variable that can be described as `multi-label`. In your final project, you might choose to work with `moods` and hence with multi-label output. You can choose to do this in several ways. One way is to use one of Python's built-in classifiers which supports Multi-Label output directly! Egs: `RandomForestClassifier`, `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "Remember how we saw that you can save anything use `.pickle`? Read in `songs_aggressive.pickle` and save it in `songs_aggressive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_aggressive = pickle.load(open('songs_aggressive.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the `type` of songs_aggressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(songs_aggressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it is a pandas DataFrame -- this means we saved a pandas dataframe as a pickle file. Nice! Print its `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>audio_features</th>\n",
       "      <th>context</th>\n",
       "      <th>decades</th>\n",
       "      <th>genres</th>\n",
       "      <th>lyrics_features</th>\n",
       "      <th>moods</th>\n",
       "      <th>name</th>\n",
       "      <th>new_context</th>\n",
       "      <th>picture</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>sub_context</th>\n",
       "      <th>yt_id</th>\n",
       "      <th>yt_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'$oid': '52fdfb3d0b9398049f3cbcdf'}</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>System Of A Down</td>\n",
       "      <td>[7, 0.906388, 0.130576, 127.438, 0.122818, 0.0...</td>\n",
       "      <td>[energetic, energetic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rock]</td>\n",
       "      <td>[wake, up, wake, up, grab, a, brush, and, put,...</td>\n",
       "      <td>[aggressive, rowdy]</td>\n",
       "      <td>Chop Suey!</td>\n",
       "      <td>energetic</td>\n",
       "      <td>http://images.musicnet.com/albums/013/354/909/...</td>\n",
       "      <td>50574.0</td>\n",
       "      <td>[energy boost, gaming ]</td>\n",
       "      <td>CSvFpBOe8eY</td>\n",
       "      <td>340810887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>{'$oid': '52fdfb3f0b9398049f3ce64d'}</td>\n",
       "      <td>Awake</td>\n",
       "      <td>Skillet</td>\n",
       "      <td>[8, 0.9567800000000001, 0.078926, 134.992, 0.0...</td>\n",
       "      <td>[gaming ]</td>\n",
       "      <td>['00s rock]</td>\n",
       "      <td>[rock]</td>\n",
       "      <td>[the, secret, side, of, me, i, never, let, you...</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>Monster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.musicnet.com/albums/032/235/853/...</td>\n",
       "      <td>10525.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1mjlM_RnsVE</td>\n",
       "      <td>125635452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>{'$oid': '52fdfb3f0b9398049f3ce638'}</td>\n",
       "      <td>B.Y.O.B. (Parental Advisory)</td>\n",
       "      <td>System Of A Down</td>\n",
       "      <td>[1, 0.9814600000000001, 0.275786, 101.799, 0.1...</td>\n",
       "      <td>[gaming ]</td>\n",
       "      <td>['00s rock]</td>\n",
       "      <td>[rock]</td>\n",
       "      <td>[you, why, do, they, always, send, the, poor, ...</td>\n",
       "      <td>[aggressive]</td>\n",
       "      <td>B.Y.O.B.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.musicnet.com/albums/003/654/455/...</td>\n",
       "      <td>50567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zUzd9KyIDrM</td>\n",
       "      <td>116388342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>{'$oid': '52fdfb3f0b9398049f3ce3bc'}</td>\n",
       "      <td>Just One Last Time</td>\n",
       "      <td>David Guetta</td>\n",
       "      <td>[8, 0.58184, 0.07976000000000001, 128.067, 0.0...</td>\n",
       "      <td>[party, party, party]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dance: house &amp; techno]</td>\n",
       "      <td>[this, is, the, end, station, but, i, cant, mo...</td>\n",
       "      <td>[visceral, aggressive, rowdy]</td>\n",
       "      <td>Just One Last Time (Feat. Taped Rai) [Extended]</td>\n",
       "      <td>work out</td>\n",
       "      <td>http://images.musicnet.com/albums/076/827/259/...</td>\n",
       "      <td>29494.0</td>\n",
       "      <td>[driving in the left lane, working out: cardio...</td>\n",
       "      <td>xyqQ4iT4IeU</td>\n",
       "      <td>109577676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>{'$oid': '52fdfb430b9398049f3d5c2e'}</td>\n",
       "      <td>...And Justice For All</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>[7, 0.690739, 0.11966099999999999, 102.132, 0....</td>\n",
       "      <td>[work out, work out]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rock]</td>\n",
       "      <td>[i, can, t, remember, anything, can, t, tell, ...</td>\n",
       "      <td>[cocky, aggressive]</td>\n",
       "      <td>One</td>\n",
       "      <td>untroubled</td>\n",
       "      <td>http://images.musicnet.com/albums/001/986/907/...</td>\n",
       "      <td>50984.0</td>\n",
       "      <td>[hanging out in the man cave, working out: wei...</td>\n",
       "      <td>EzgGTTtR0kc</td>\n",
       "      <td>98703416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _id                         album  \\\n",
       "47   {'$oid': '52fdfb3d0b9398049f3cbcdf'}                      Toxicity   \n",
       "182  {'$oid': '52fdfb3f0b9398049f3ce64d'}                         Awake   \n",
       "201  {'$oid': '52fdfb3f0b9398049f3ce638'}  B.Y.O.B. (Parental Advisory)   \n",
       "212  {'$oid': '52fdfb3f0b9398049f3ce3bc'}            Just One Last Time   \n",
       "249  {'$oid': '52fdfb430b9398049f3d5c2e'}        ...And Justice For All   \n",
       "\n",
       "               artist                                     audio_features  \\\n",
       "47   System Of A Down  [7, 0.906388, 0.130576, 127.438, 0.122818, 0.0...   \n",
       "182           Skillet  [8, 0.9567800000000001, 0.078926, 134.992, 0.0...   \n",
       "201  System Of A Down  [1, 0.9814600000000001, 0.275786, 101.799, 0.1...   \n",
       "212      David Guetta  [8, 0.58184, 0.07976000000000001, 128.067, 0.0...   \n",
       "249         Metallica  [7, 0.690739, 0.11966099999999999, 102.132, 0....   \n",
       "\n",
       "                    context      decades                   genres  \\\n",
       "47   [energetic, energetic]           []                   [rock]   \n",
       "182               [gaming ]  ['00s rock]                   [rock]   \n",
       "201               [gaming ]  ['00s rock]                   [rock]   \n",
       "212   [party, party, party]           []  [dance: house & techno]   \n",
       "249    [work out, work out]           []                   [rock]   \n",
       "\n",
       "                                       lyrics_features  \\\n",
       "47   [wake, up, wake, up, grab, a, brush, and, put,...   \n",
       "182  [the, secret, side, of, me, i, never, let, you...   \n",
       "201  [you, why, do, they, always, send, the, poor, ...   \n",
       "212  [this, is, the, end, station, but, i, cant, mo...   \n",
       "249  [i, can, t, remember, anything, can, t, tell, ...   \n",
       "\n",
       "                             moods  \\\n",
       "47             [aggressive, rowdy]   \n",
       "182                   [aggressive]   \n",
       "201                   [aggressive]   \n",
       "212  [visceral, aggressive, rowdy]   \n",
       "249            [cocky, aggressive]   \n",
       "\n",
       "                                                name new_context  \\\n",
       "47                                        Chop Suey!   energetic   \n",
       "182                                          Monster         NaN   \n",
       "201                                         B.Y.O.B.         NaN   \n",
       "212  Just One Last Time (Feat. Taped Rai) [Extended]    work out   \n",
       "249                                              One  untroubled   \n",
       "\n",
       "                                               picture  recording_id  \\\n",
       "47   http://images.musicnet.com/albums/013/354/909/...       50574.0   \n",
       "182  http://images.musicnet.com/albums/032/235/853/...       10525.0   \n",
       "201  http://images.musicnet.com/albums/003/654/455/...       50567.0   \n",
       "212  http://images.musicnet.com/albums/076/827/259/...       29494.0   \n",
       "249  http://images.musicnet.com/albums/001/986/907/...       50984.0   \n",
       "\n",
       "                                           sub_context        yt_id   yt_views  \n",
       "47                             [energy boost, gaming ]  CSvFpBOe8eY  340810887  \n",
       "182                                                NaN  1mjlM_RnsVE  125635452  \n",
       "201                                                NaN  zUzd9KyIDrM  116388342  \n",
       "212  [driving in the left lane, working out: cardio...  xyqQ4iT4IeU  109577676  \n",
       "249  [hanging out in the man cave, working out: wei...  EzgGTTtR0kc   98703416  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_aggressive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a `train_test_split`. We want our features (`X`) to be our `audio_features` from `songs_aggressive`.<br>\n",
    "**Note:** A quick way to get your features into a list format for the `train_test_split` from the pandas Series format is to use `.values.tolist()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = songs_aggressive['audio_features'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our labels, `y`,  to be the `moods` from `songs_aggressive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = songs_aggressive['moods']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47                               [aggressive, rowdy]\n",
      "182                                     [aggressive]\n",
      "201                                     [aggressive]\n",
      "212                    [visceral, aggressive, rowdy]\n",
      "249                              [cocky, aggressive]\n",
      "287                      [cocky, aggressive, trashy]\n",
      "298                                     [aggressive]\n",
      "440                               [cold, aggressive]\n",
      "446                                     [aggressive]\n",
      "481                                     [aggressive]\n",
      "519      [cocky, aggressive, visceral, motivational]\n",
      "520                                     [aggressive]\n",
      "522                             [angsty, aggressive]\n",
      "543                                     [aggressive]\n",
      "576                                     [aggressive]\n",
      "580                      [cocky, aggressive, trashy]\n",
      "589                              [aggressive, rowdy]\n",
      "593                                     [aggressive]\n",
      "601                                [aggressive, raw]\n",
      "626                                     [aggressive]\n",
      "632                                     [aggressive]\n",
      "638                              [aggressive, rowdy]\n",
      "639                                     [aggressive]\n",
      "642                      [cocky, aggressive, trashy]\n",
      "656                                     [aggressive]\n",
      "703            [cocky, angsty, aggressive, visceral]\n",
      "709                                     [aggressive]\n",
      "710                               [cold, aggressive]\n",
      "793                                     [aggressive]\n",
      "796                                     [aggressive]\n",
      "                            ...                     \n",
      "35405               [angsty, aggressive, rowdy, raw]\n",
      "35414                                   [aggressive]\n",
      "35424                                   [aggressive]\n",
      "35438               [angsty, aggressive, rowdy, raw]\n",
      "35501                    [angsty, aggressive, rowdy]\n",
      "35515                    [angsty, aggressive, rowdy]\n",
      "35517        [energetic, angsty, aggressive, trashy]\n",
      "35578                    [angsty, aggressive, rowdy]\n",
      "35602               [angsty, aggressive, rowdy, raw]\n",
      "35626                                   [aggressive]\n",
      "35645                                   [aggressive]\n",
      "35648                    [angsty, aggressive, rowdy]\n",
      "35668                             [cold, aggressive]\n",
      "35728                                   [aggressive]\n",
      "35738                             [cold, aggressive]\n",
      "35759                           [angsty, aggressive]\n",
      "35775                             [cold, aggressive]\n",
      "35796        [energetic, angsty, aggressive, trashy]\n",
      "36044                     [aggressive, motivational]\n",
      "36048                           [angsty, aggressive]\n",
      "36055                         [aggressive, visceral]\n",
      "36061                           [angsty, aggressive]\n",
      "36068                           [angsty, aggressive]\n",
      "36076                                   [aggressive]\n",
      "36077                           [angsty, aggressive]\n",
      "36128                           [angsty, aggressive]\n",
      "36314        [energetic, angsty, aggressive, trashy]\n",
      "36318        [energetic, angsty, aggressive, trashy]\n",
      "36359                    [angsty, aggressive, rowdy]\n",
      "36417                     [aggressive, motivational]\n",
      "Name: moods, Length: 1938, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that, for many entries, there are multiple labels. For example, for index `36359`, the label has 3 values: <br>`['angsty', 'aggressive', 'rowdy']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we want to do is convert our labels into numbers. Remember, computers always work with numbers!!! We will do this using the `MultiLabelBinarizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.preprocessing` import `MultiLabelBinarizer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new instance of `MultiLabelBinarizer()` and save it in `mlb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `.fit_transform` on our labels above (`y`). Store it in `y_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print y_labels to see what it looks like. It should look like a bunch of lists with 1s and 0s. Each list is a label that has been converted into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 1 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 1 0 ... 0 1 0]\n",
      " [1 1 0 ... 1 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `mlb.classes_`, `y_labels[0]`, and `y.iloc[0]` and compare them. You will notice how the labels have been encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggressive' 'angsty' 'cocky' 'cold' 'energetic' 'motivational' 'raw'\n",
      " 'rowdy' 'trashy' 'visceral']\n",
      "[1 0 0 0 0 0 0 1 0 0]\n",
      "['aggressive', 'rowdy']\n"
     ]
    }
   ],
   "source": [
    "print(mlb.classes_)\n",
    "print(y_labels[0])\n",
    "print(y.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because we are going to use a `KNeighborsClassifier`, we need to scale our features. Use a `StandardScaler` to scale `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create our `train_test_split`! Use `test_size=0.1`, `random_state=42`, `X`, and `y_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create your `KNeighborsClassifier`, `.fit` it to the training data, call `.predict` and print the `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       194\n",
      "          1       0.54      0.35      0.42        72\n",
      "          2       0.57      0.14      0.22        29\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.00      0.00      0.00        19\n",
      "          5       0.50      0.09      0.15        11\n",
      "          6       0.38      0.11      0.17        27\n",
      "          7       0.43      0.11      0.17        28\n",
      "          8       0.50      0.11      0.17        38\n",
      "          9       0.15      0.07      0.10        27\n",
      "\n",
      "avg / total       0.67      0.53      0.56       449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_multi = KNeighborsClassifier()\n",
    "knn_multi.fit(X_train, y_train)\n",
    "knn_multi_label_predictions = knn_multi.predict(X_test)\n",
    "print(classification_report(y_test, knn_multi_label_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Chains\n",
    "\n",
    "Classifier Chains are a way to combine many multi-label classifiers together in a way such that each classifier in the chain gets the output of the previous classifier and uses it as a feature! This might be helpful if your labels are co-related. Moods are probably co-related, so let's see if it helps.\n",
    "\n",
    "Let's try it out on our current dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.multioutput` import `ClassifierChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ClassifierChain` takes in as an argument the kind of classifier you want to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ClassifierChain(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now `.fit` and `.predict` on your chain just like you would a normal classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       194\n",
      "          1       0.54      0.35      0.42        72\n",
      "          2       0.44      0.14      0.21        29\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.00      0.00      0.00        19\n",
      "          5       0.50      0.09      0.15        11\n",
      "          6       0.50      0.22      0.31        27\n",
      "          7       0.57      0.14      0.23        28\n",
      "          8       0.67      0.16      0.26        38\n",
      "          9       0.25      0.15      0.19        27\n",
      "\n",
      "avg / total       0.70      0.54      0.58       449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain.fit(X_train, y_train)\n",
    "predictions = chain.predict(X_test)\n",
    "report = classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you observe? Did your score improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that, the number of classifiers in the chain will be equal to the number of labels! You can check this by comparing `len(chain.estimators_)` and `len(mlb.classes_)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(chain.estimators_))\n",
    "print(len(mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also useful to know that the *order* of the classifiers inside the chain is important and can probably influence your results. Check the python [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html) and [example](http://scikit-learn.org/stable/auto_examples/multioutput/plot_classifier_chain_yeast.html#sphx-glr-auto-examples-multioutput-plot-classifier-chain-yeast-py) for the parameters you can pass to your chain.\n",
    "\n",
    "For more info, you can also check out section 4.1.2 on Classifier Chains in this [article](https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Binary Classifiers and looking at Probabilities\n",
    "\n",
    "Another technique you can try is to instead use individual binary classifiers and look at the probability of their predictions. This can help you do things like declare the *top* 3 moods for example. You can also use the probabilities in the calculation of your similarity score, when deciding which songs are more similar than others to your test song.\n",
    "\n",
    "Let's take a quick look at how to inspect the probability for a prediction, using a `RandomForestClassifier` as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "\n",
    "We'll work with `genres` here, as in Assignment 1. Read in `Consolidated_Dance_Jazz.csv`, which contains all the audio features and the genres for `Dance` and `Jazz` songs. Store it in `songs_dance_jazz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>mode</th>\n",
       "      <th>time_signature_confidence</th>\n",
       "      <th>tempo_confidence</th>\n",
       "      <th>key_confidence</th>\n",
       "      <th>mode_confidence</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.705822</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>126.009</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194.09333</td>\n",
       "      <td>-3.898</td>\n",
       "      <td>0.592798</td>\n",
       "      <td>0.875137</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.742</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>0.171423</td>\n",
       "      <td>130.009</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.058936</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>284.41333</td>\n",
       "      <td>-7.443</td>\n",
       "      <td>0.476111</td>\n",
       "      <td>0.789760</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.000</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.728367</td>\n",
       "      <td>0.844810</td>\n",
       "      <td>112.328</td>\n",
       "      <td>0.307629</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>207.15057</td>\n",
       "      <td>-14.511</td>\n",
       "      <td>0.652412</td>\n",
       "      <td>0.691151</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.687771</td>\n",
       "      <td>0.890427</td>\n",
       "      <td>118.388</td>\n",
       "      <td>0.069611</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>357.80000</td>\n",
       "      <td>-9.815</td>\n",
       "      <td>0.781912</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.815</td>\n",
       "      <td>1.000</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.061545</td>\n",
       "      <td>122.677</td>\n",
       "      <td>0.066457</td>\n",
       "      <td>0.038270</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>267.16000</td>\n",
       "      <td>-6.094</td>\n",
       "      <td>0.552483</td>\n",
       "      <td>0.844630</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1.000</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key    energy  liveliness    tempo  speechiness  acousticness  \\\n",
       "0   3.0  0.705822    0.053292  126.009     0.126016      0.001966   \n",
       "1   0.0  0.616411    0.171423  130.009     0.059577      0.058936   \n",
       "2   7.0  0.728367    0.844810  112.328     0.307629      0.009750   \n",
       "3  11.0  0.687771    0.890427  118.388     0.069611      0.031731   \n",
       "4   6.0  0.650609    0.061545  122.677     0.066457      0.038270   \n",
       "\n",
       "   instrumentalness  time_signature  duration   loudness  valence  \\\n",
       "0          0.000000             0.0       4.0  194.09333   -3.898   \n",
       "1          0.000065             1.0       4.0  284.41333   -7.443   \n",
       "2          0.000022             1.0       4.0  207.15057  -14.511   \n",
       "3          0.000222             1.0       4.0  357.80000   -9.815   \n",
       "4          0.000030             0.0       4.0  267.16000   -6.094   \n",
       "\n",
       "   danceability      mode  time_signature_confidence  tempo_confidence  \\\n",
       "0      0.592798  0.875137                      0.004             0.114   \n",
       "1      0.476111  0.789760                      0.499             0.489   \n",
       "2      0.652412  0.691151                      0.844             0.384   \n",
       "3      0.781912  0.771293                      0.851             0.534   \n",
       "4      0.552483  0.844630                      0.550             0.550   \n",
       "\n",
       "   key_confidence  mode_confidence genres  \n",
       "0           1.000            0.742  dance  \n",
       "1           0.708            1.000  dance  \n",
       "2           1.000            1.000  dance  \n",
       "3           0.815            1.000  dance  \n",
       "4           0.766            1.000  dance  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_dance_jazz = pd.read_csv('Consolidated_Dance_Jazz.csv')\n",
    "songs_dance_jazz.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following steps:\n",
    "* Build a `LogisticRegression` classifier called `logReg`.\n",
    "* Make a `train_test_split` with `test_size=0.33, random_state=42`. \n",
    "* Use all the audio features as features.\n",
    "    * Remember to scale your features!\n",
    "* Use `genres` as the labels.\n",
    "* `.fit`, `.predict`, and print the `classification_report` for `logReg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      dance       0.94      0.96      0.95       682\n",
      "       jazz       0.95      0.94      0.94       602\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression()\n",
    "X = songs_dance_jazz.drop('genres', axis=1)\n",
    "y = songs_dance_jazz['genres']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "logReg.fit(X_train, y_train)\n",
    "predictions = logReg.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an `f1-score` of around `0.95`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities\n",
    "\n",
    "Let's look at the song at index 20 and see what the prediction probabilities were!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dance'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.predict(X_test[20].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the classifier predicted the song at index 20 as `dance`. How confident was it? We use the `predict_proba` method to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80143092, 0.19856908]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.predict_proba(X_test[20].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that it was around `80.14 %` sure that it was a `dance` song, and `19.86 %` sure it was `jazz`\n",
    "\n",
    "To see the classes themselves, you can simply print `logReg.classes_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dance', 'jazz'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers\n",
    "\n",
    "Voting Classifiers are a convenient way to simply group many classifiers together, and take the result that most of them predict. Let's see this with a quick example using 3 classifiers: `KNearestNeighbors`, `SVC`, and `LogisticRegression`.\n",
    "\n",
    "Do the following:\n",
    "* Create a KNearestNeighbors Classifier\n",
    "* Create a SVC (Support Vector Machine Classifier)\n",
    "* Create a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "logReg = LogisticRegression()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the same `X_train` / `X_test` / `y_train` / `y_test` as before, fit all your classifiers to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "logReg.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: Let us look at the prediction each classifier has for the song at index `20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dance']\n",
      "['jazz']\n",
      "['dance']\n"
     ]
    }
   ],
   "source": [
    "song_index = 20\n",
    "print(logReg.predict(X_test[song_index].reshape(1,-1))) # Logistic Regression prediction\n",
    "print(knn.predict(X_test[song_index].reshape(1,-1))) # kNN prediction\n",
    "print(svc.predict(X_test[song_index].reshape(1,-1))) # Support Vector Machine Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `kNN` predicted the song as `jazz`, while the other 2 predicted the song as `dance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do is create a `VotingClassifier` that has these 3 classifiers, and its output will automatically be the most popular prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.ensemble` import `VotingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `VotingClassifier` that contains all your above classifiers! It requires you pass in a `list` of your classifiers, each element in the list with the following syntax:\n",
    "\n",
    "`(<some name for your classifier>, <your classifier object>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier([('log_regression', logReg), ('knn', knn), ('svc', svc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `.fit` your `voting_classifier` on `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('log_regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the prediction for song at index 19 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dance'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier.predict(X_test[song_index].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it is `dance`! This is because it was the majority vote from the previous 3 classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "If you decide to use the **Million Song DataSet** *(MSD)*, you won't have any mood information (unless you try to use the *MSD* and `MasterSongList.json` together ;)). In this case, one very popular similarity metric is called *cosine similarity*. It basically decides that 2 vectors are similar if they are close together to each other. You can learn more about cosine similarity in this [picture](https://lh5.googleusercontent.com/lYq5EWtpgku57oUGff4oBcQWNaxmvj9IIXGF7_ILr9uA1wgvlI0_j8dYc00)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 3 sentences that are similar. We'll make sentence_1 and sentence_2 more 'similar' to each other than sentence_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Mason really loves food\"\n",
    "sentence_2 = \"Hannah loves food too\"\n",
    "sentence_3 = \"The pizza is food\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's create a bag of words model using `CountVectorizer` and the above sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer()\n",
    "all_sentences = [sentence_1, sentence_2, sentence_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = count_vec.fit_transform(all_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from `sklearn.metrics.pairwise` import `cosine_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how 'similar' sentence_1 and sentence_2 are. Remember that the feature vectors for these sentences live inside our `bag_of_words` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(bag_of_words[0], bag_of_words[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see a value of `0.5`, which means they are pretty similar!\n",
    "\n",
    "What about sentence_1 and sentence_3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(bag_of_words[0], bag_of_words[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a value of `0.25`, which means they are not as similar.\n",
    "\n",
    "Remember, a value of `1` and the closer the value gets to `0` it means they are not the same. `-1` means they are the 'opposite' !\n",
    "\n",
    "OK, that's it for now. All the best with the final project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Label Classification: Yelp Example**<br>\n",
    "http://mondego.ics.uci.edu/projects/yelp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python page on Multi-Label and Multi-Class Classification**<br>\n",
    "http://scikit-learn.org/stable/modules/multiclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV & Pipeline: Example**<br>\n",
    "https://www.civisanalytics.com/blog/workflows-in-python-using-pipeline-and-gridsearchcv-for-more-compact-and-comprehensive-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Chains**<br>\n",
    "https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/ (see section 4.1.2)<br>\n",
    "http://scikit-learn.org/stable/auto_examples/multioutput/plot_classifier_chain_yeast.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
